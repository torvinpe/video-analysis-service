**Note:** Main code repository is here:
<https://github.com/mvsjober/video-analysis-service>

# Installation

```bash
sudo apt-get install redis
pip install flask celery[redis]
```

# Usage

Important: `--concurrency=1` flag to celery so that it runs only one job at a
time. Flag `-P threads` is needed as some DeepLabCut processing uses multi-threading.

```bash
sudo systemctl start redis
celery -A app.celery worker --concurrency=1 -P threads
flask run  # in separate terminal
```

For development, `export FLASK_ENV=development` might also be handy. Before the
first run you also need to initialize the sqlite3 database with `flask init-db`.

Testing upload (example):

```bash
curl -F "file=@hello.txt" http://127.0.0.1:5000/file
```

Note that [for DeepLabCut I had to reencode my videos][reencode], for example
like this:

```bash
ffmpeg -i video.avi -c:v libx265 -preset fast -crf 18 video_reencoded.mp4
```

Start analysis (example):

```bash
curl -d file_id=7b4758d4 -d analysis=sleep -d time=10 http://127.0.0.1:5000/analysis
```

Check results (example):

```bash
curl http://127.0.0.1:5000/analysis/32355caf-f322-4b05-b1c2-878d1e9be272
```

Fetch resulting file (example):

```bash
curl http://127.0.0.1:5000/file/234c49f658aceaeb72f7c366ca386167150058d3 -o output.mp4
```


# Deployment

There are some [notes on deployment on a server in a separate file](deployment.md).

# API

## Upload file for analysis

The response will contain a `file_id` identifier (generated by server) which can
later be used to refer to the uploaded file.

POST `/file`

Payload: multipart/form-data format, file as `file` parameter

Response (example):

    HTTP 200
    { file_id: 123 }
    
## List uploaded files

GET `/file`

## Download specific file

GET `/file/<file_id>`

The given file id can be the first characters of the SHA1, returned if there is
a single unambiguous match.

## Delete file

DELETE `/file/<file_id>`


## Start analysis for file

Start analysis for previously uploaded file. In theory we could start many
different types of analyses for the same file. Response will give `analysis_id`,
an identifier for later accessing the analysis results.

POST `/analysis`

Parameters (multipart/form-data format):

- `file_id` file id as received when uploading file
- `analysis` name of analysis
- `model` name of model

The rest of the parameters can be used as arguments for the analysis.

Currently supported values for `analysis` names:

- `video`: runs `deeplabcut.analyze_videos` for given video file
- `label`: runs `deeplabcut.create_labeled_video` for given video file
- `image`: runs `deeplabcut.analyze_time_lapse_frames`for given image file
- `label-image`: label given image file using OpenCV
- `triangulate`: **TODO** `deeplabcut.triangulate`
- `label_3d`: **TODO** `deeplabcut.create_labeled_video_3d`

Currently supported values for `model` names:

- `wassu-cam0`
- `prone-shooting`


Response (HTTP 200):

    { analysis_id: 42 }

## List all analyses files

GET `/analysis`

**NOTE:** the state (PENDING, STARTED, FAILURE, SUCCESS) may be old as this
command does not query Celery for the current state. The state in the database
is updated only when calling GET `/analysis/<analysis_id` explicitly for a
specific analysis.

## Get analysis

Endpoint to poll if results are ready yet. We respond perhaps with HTTP 202 and
empty content if no result yet (but the analysis_id was a valid one). When result
is ready we return (HTTP 200) the results as JSON. The result can contain links to
files related to the analysis which need to be downloaded separately.

GET `/analysis/<analysis_id>`

Response (not ready yet):

    HTTP 202

Response (ready, HTTP 200):

    {
        result: [0.2, 0.99, -4.0],
        video_file: afa468f55c2d7a9ba62da5a1b33caa55d393c730,
    }

Files are given as hashes, which you can fetch with `GET /file/<sha1_hash>`


[reencode]: https://deeplabcut.github.io/DeepLabCut/docs/recipes/io.html#tips-on-video-re-encoding-and-preprocessing
